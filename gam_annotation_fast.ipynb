{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A simple user interface for XMem\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION\"] = \"python\"\n",
    "\n",
    "import cv2\n",
    "import sys\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "import shutil\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from easydict import EasyDict\n",
    "\n",
    "from orion.utils.misc_utils import (\n",
    "    load_first_frame_from_hdf5_dataset, \n",
    "    export_video_from_hdf5_dataset,\n",
    "    load_first_frame_from_human_hdf5_dataset, \n",
    "    export_video_from_human_hdf5_dataset,\n",
    "    overlay_xmem_mask_on_image,\n",
    "    )\n",
    "from orion.algos.grounded_sam_wrapper import GroundedSamWrapper\n",
    "\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "wrapper = GroundedSamWrapper()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "# image = np.array(Image.open(\"example_image.png\"))\n",
    "image = np.array(Image.open(\"example_image.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_mask_image = wrapper.segment(image, [\"a photo of a man\", \"a photo of humanoid robot\", \"a photo of door\", \"windows\"])\n",
    "final_mask_image = wrapper.segment(image, [\"humanoid robot\"])\n",
    "\n",
    "overlay_image = overlay_xmem_mask_on_image(image, np.array(final_mask_image), use_white_bg=True, rgb_alpha=0.3)\n",
    "plt.imshow(overlay_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "args = EasyDict({\n",
    "    \"image\": None,\n",
    "    \"video\": None,\n",
    "    \"demo\": None,\n",
    "    \"rollout\": None,\n",
    "    # \"human_demo\": \"iphone_place_chip_bag_on_plate_1_demo.hdf5\",\n",
    "    # \"text\": [\"chip bag\", \"plate\"],\n",
    "    # \"human_demo\": \"iphone_pick_place_blue_mug_1_demo.hdf5\",\n",
    "    # \"text\": [\"mug\", \"coaster\"]\n",
    "    # \"human_demo\": \"iphone_front_boat/iphone_front_boat_demo.hdf5\",\n",
    "    # \"text\": [\"small red block\", \"boat body\"]\n",
    "    # \"human_demo\": \"long_horizon/long_horizon_rearrangement_cheese_4_demo.hdf5\",\n",
    "    # \"text\": [\"chip bag\", \"plate\", \"coaster\", \"mug\"]\n",
    "    \"human_demo\": \"long_horizon_boat/iphone_long_horizon_boat_18_demo.hdf5\",\n",
    "    \"text\": [\"boat chimney\", \"red blocks\", \"red boat\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "args.human_demo = os.path.join(\"datasets/iphones\", args.human_demo)\n",
    "\n",
    "def run():\n",
    "    mode = \"\"\n",
    "    if args.image is not None:\n",
    "        mode = \"image\"\n",
    "    elif args.video is not None:\n",
    "        mode = \"video\"\n",
    "    elif args.demo is not None:\n",
    "        mode = \"demo\"\n",
    "    elif args.human_demo is not None:\n",
    "        mode = \"human_demo\"\n",
    "    elif args.rollout is not None:\n",
    "        mode = \"rollout\"\n",
    "\n",
    "    annotation_folder = f\"annotations/{mode}\"\n",
    "    tmp_folder = \"tmp_images\"\n",
    "\n",
    "    if mode == \"image\":\n",
    "        annotation_path = os.path.join(annotation_folder, args.image.split(\"/\")[-1].split(\".\")[0])\n",
    "    elif mode == \"video\":\n",
    "        annotation_path = os.path.join(annotation_folder, args.video.split(\"/\")[-1].split(\".\")[0])\n",
    "    elif mode == \"demo\":\n",
    "        annotation_path = os.path.join(annotation_folder, args.demo.split(\"/\")[-1].split(\".\")[0])\n",
    "    elif mode == \"human_demo\":\n",
    "        annotation_path = os.path.join(annotation_folder, args.human_demo.split(\"/\")[-1].split(\".\")[0])\n",
    "    elif mode == \"rollout\":\n",
    "        annotation_path = os.path.join(annotation_folder, args.rollout.split(\"/\")[-1].split(\".\")[0])\n",
    "\n",
    "    tmp_path = tmp_folder\n",
    "\n",
    "\n",
    "    os.makedirs(annotation_path, exist_ok=True)\n",
    "    os.makedirs(tmp_path, exist_ok=True)\n",
    "    os.makedirs(os.path.join(tmp_path, \"images\"), exist_ok=True)\n",
    "\n",
    "    if mode == \"image\":\n",
    "        first_frame = cv2.imread(args.image)\n",
    "    elif mode == \"rollout\":\n",
    "        first_frame = cv2.imread(args.rollout)\n",
    "    elif mode == \"video\":\n",
    "        _, first_frame = cv2.VideoCapture(args.video).read()\n",
    "    elif mode == \"demo\":\n",
    "        first_frame = load_first_frame_from_hdf5_dataset(args.demo, demo_idx=args.demo_idx, bgr=True)\n",
    "    elif mode == \"human_demo\":\n",
    "        first_frame = load_first_frame_from_human_hdf5_dataset(args.human_demo, bgr=True)\n",
    "\n",
    "    cv2.imwrite(os.path.join(os.path.join(tmp_path, \"images\", \"frame.jpg\")), first_frame)\n",
    "\n",
    "    args.images = tmp_path\n",
    "    args.workspace = tmp_path\n",
    "\n",
    "    print(args.images, tmp_folder)\n",
    "\n",
    "    # launch_gui(args)\n",
    "    print(\"Annotating the image with text input: \", args.text)\n",
    "\n",
    "    final_mask_image = wrapper.segment(first_frame, args.text)\n",
    "    os.makedirs(os.path.join(tmp_path, \"masks\"), exist_ok=True)\n",
    "    final_mask_image.save(os.path.join(tmp_path, \"masks\", \"frame.png\"))\n",
    "    overlay_image = overlay_xmem_mask_on_image(first_frame, np.array(final_mask_image), use_white_bg=True, rgb_alpha=0.3)\n",
    "\n",
    "    try:\n",
    "        plt.imshow(overlay_image)\n",
    "        plt.show()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # copy a image from a folder to another\n",
    "    shutil.copyfile(os.path.join(tmp_path, \"images\", \"frame.jpg\"), os.path.join(annotation_path, \"frame.jpg\"))\n",
    "    shutil.copyfile(os.path.join(tmp_path, \"masks\", \"frame.png\"), os.path.join(annotation_path, \"frame_annotation.png\"))\n",
    "    print(\"Annotation saved to \", os.path.join(annotation_path, \"frame_annotation.png\"))\n",
    "    with open(os.path.join(annotation_path, \"config.json\"), \"w\") as f:\n",
    "        config_dict = {\"mode\": mode}\n",
    "        if mode == \"image\":\n",
    "            config_dict[\"original_file\"] = args.image\n",
    "        elif mode == \"rollout\":\n",
    "            config_dict[\"original_file\"] = args.rollout            \n",
    "        elif mode == \"video\":\n",
    "            config_dict[\"original_file\"] = args.video\n",
    "            config_dict[\"video_file\"] = args.video\n",
    "        elif mode == \"demo\":\n",
    "            config_dict[\"original_file\"] = args.demo\n",
    "            video_path = export_video_from_hdf5_dataset(\n",
    "                            dataset_name=args.demo, \n",
    "                            demo_idx=args.demo_idx,\n",
    "                            video_path=annotation_path,\n",
    "                            video_name=args.demo.split(\"/\")[-1].split(\".\")[0],\n",
    "                            bgr=True)\n",
    "            config_dict[\"video_file\"] = video_path\n",
    "        elif mode == \"human_demo\":\n",
    "            config_dict[\"original_file\"] = args.human_demo\n",
    "            video_path = export_video_from_human_hdf5_dataset(\n",
    "                            dataset_name=args.human_demo, \n",
    "                            video_path=annotation_path,\n",
    "                            video_name=args.human_demo.split(\"/\")[-1].split(\".\")[0],\n",
    "                            bgr=True)\n",
    "            config_dict[\"video_file\"] = video_path\n",
    "        config_dict[\"text\"] = args.text\n",
    "        json.dump(config_dict, f)\n",
    "    # remove the folder\n",
    "    shutil.rmtree(tmp_path)\n",
    "\n",
    "\n",
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
