{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# conda environments:\n",
      "#\n",
      "base                     /home/yifengz/miniconda3\n",
      "dinov2                *  /home/yifengz/miniconda3/envs/dinov2\n",
      "gr1-test                 /home/yifengz/miniconda3/envs/gr1-test\n",
      "hamer                    /home/yifengz/miniconda3/envs/hamer\n",
      "humanoid                 /home/yifengz/miniconda3/envs/humanoid\n",
      "robosuite-usd            /home/yifengz/miniconda3/envs/robosuite-usd\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda env list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Cannot initialize a EGL device display. This likely means that your EGL driver does not support the PLATFORM_DEVICE extension, which is required for creating a headless rendering context.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39morion\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39malgos\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mhuman_video_oogs\u001b[39;00m \u001b[39mimport\u001b[39;00m HumanVideoOOGs\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39morion\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39malgos\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moog\u001b[39;00m \u001b[39mimport\u001b[39;00m OpenWorldObjectSceneGraph\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39morion\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmisc_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "File \u001b[0;32m~/workspace_ljh/ORION/orion/algos/human_video_oogs.py:7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m \u001b[39mimport\u001b[39;00m StandardScaler\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mhausdorff\u001b[39;00m \u001b[39mimport\u001b[39;00m hausdorff_distance\n\u001b[0;32m----> 7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mrobosuite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtransform_utils\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mrobosuite_transform\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[39m# mp\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmultiprocessing\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mmp\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dinov2/lib/python3.9/site-packages/robosuite/utils/transform_utils.py:11\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmath\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mrobosuite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnumba\u001b[39;00m \u001b[39mimport\u001b[39;00m jit_decorator\n\u001b[1;32m     13\u001b[0m PI \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mpi\n\u001b[1;32m     14\u001b[0m EPS \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mfinfo(\u001b[39mfloat\u001b[39m)\u001b[39m.\u001b[39meps \u001b[39m*\u001b[39m \u001b[39m4.0\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/dinov2/lib/python3.9/site-packages/robosuite/utils/numba.py:6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mNumba utils.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumba\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mrobosuite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmacros\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mmacros\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mjit_decorator\u001b[39m(func):\n\u001b[1;32m     10\u001b[0m     \u001b[39mif\u001b[39;00m macros\u001b[39m.\u001b[39mENABLE_NUMBA:\n",
      "File \u001b[0;32m~/miniconda3/envs/dinov2/lib/python3.9/site-packages/robosuite/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mrobosuite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39menvironments\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbase\u001b[39;00m \u001b[39mimport\u001b[39;00m make\n\u001b[1;32m      3\u001b[0m \u001b[39m# Manipulation environments\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mrobosuite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39menvironments\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmanipulation\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlift\u001b[39;00m \u001b[39mimport\u001b[39;00m Lift\n",
      "File \u001b[0;32m~/miniconda3/envs/dinov2/lib/python3.9/site-packages/robosuite/environments/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbase\u001b[39;00m \u001b[39mimport\u001b[39;00m REGISTERED_ENVS, MujocoEnv\n\u001b[1;32m      3\u001b[0m ALL_ENVIRONMENTS \u001b[39m=\u001b[39m REGISTERED_ENVS\u001b[39m.\u001b[39mkeys()\n",
      "File \u001b[0;32m~/miniconda3/envs/dinov2/lib/python3.9/site-packages/robosuite/environments/base.py:12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mrobosuite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mrenderers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbase\u001b[39;00m \u001b[39mimport\u001b[39;00m load_renderer_config\n\u001b[1;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mrobosuite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m OpenCVRenderer, SimulationError, XMLError\n\u001b[0;32m---> 12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mrobosuite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbinding_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m MjRenderContextOffscreen, MjSim\n\u001b[1;32m     14\u001b[0m REGISTERED_ENVS \u001b[39m=\u001b[39m {}\n\u001b[1;32m     17\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mregister_env\u001b[39m(target_class):\n",
      "File \u001b[0;32m~/miniconda3/envs/dinov2/lib/python3.9/site-packages/robosuite/utils/binding_utils.py:58\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mrobosuite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mrenderers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcontext\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mosmesa_context\u001b[39;00m \u001b[39mimport\u001b[39;00m OSMesaGLContext \u001b[39mas\u001b[39;00m GLContext\n\u001b[1;32m     57\u001b[0m \u001b[39melif\u001b[39;00m _SYSTEM \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mLinux\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m _MUJOCO_GL \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39megl\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m---> 58\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mrobosuite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mrenderers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcontext\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39megl_context\u001b[39;00m \u001b[39mimport\u001b[39;00m EGLGLContext \u001b[39mas\u001b[39;00m GLContext\n\u001b[1;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mrobosuite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mrenderers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcontext\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mglfw_context\u001b[39;00m \u001b[39mimport\u001b[39;00m GLFWGLContext \u001b[39mas\u001b[39;00m GLContext\n",
      "File \u001b[0;32m~/miniconda3/envs/dinov2/lib/python3.9/site-packages/robosuite/renderers/context/egl_context.py:32\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39melif\u001b[39;00m PYOPENGL_PLATFORM\u001b[39m.\u001b[39mlower() \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39megl\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m     26\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[1;32m     27\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot use EGL rendering platform. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     28\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe PYOPENGL_PLATFORM environment variable is set to \u001b[39m\u001b[39m{!r}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     29\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m(should be either unset or \u001b[39m\u001b[39m'\u001b[39m\u001b[39megl\u001b[39m\u001b[39m'\u001b[39m\u001b[39m).\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     30\u001b[0m     )\n\u001b[0;32m---> 32\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmujoco\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39megl\u001b[39;00m \u001b[39mimport\u001b[39;00m egl_ext \u001b[39mas\u001b[39;00m EGL\n\u001b[1;32m     33\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mOpenGL\u001b[39;00m \u001b[39mimport\u001b[39;00m error\n\u001b[1;32m     36\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_initialized_egl_device_display\u001b[39m(device_id\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/dinov2/lib/python3.9/site-packages/mujoco/egl/__init__.py:67\u001b[0m\n\u001b[1;32m     65\u001b[0m EGL_DISPLAY \u001b[39m=\u001b[39m create_initialized_egl_device_display()\n\u001b[1;32m     66\u001b[0m \u001b[39mif\u001b[39;00m EGL_DISPLAY \u001b[39m==\u001b[39m EGL\u001b[39m.\u001b[39mEGL_NO_DISPLAY:\n\u001b[0;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[1;32m     68\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mCannot initialize a EGL device display. This likely means that your EGL \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     69\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mdriver does not support the PLATFORM_DEVICE extension, which is \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     70\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mrequired for creating a headless rendering context.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     71\u001b[0m atexit\u001b[39m.\u001b[39mregister(EGL\u001b[39m.\u001b[39meglTerminate, EGL_DISPLAY)\n\u001b[1;32m     74\u001b[0m EGL_ATTRIBUTES \u001b[39m=\u001b[39m (\n\u001b[1;32m     75\u001b[0m     EGL\u001b[39m.\u001b[39mEGL_RED_SIZE, \u001b[39m8\u001b[39m,\n\u001b[1;32m     76\u001b[0m     EGL\u001b[39m.\u001b[39mEGL_GREEN_SIZE, \u001b[39m8\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     84\u001b[0m     EGL\u001b[39m.\u001b[39mEGL_NONE\n\u001b[1;32m     85\u001b[0m )\n",
      "\u001b[0;31mImportError\u001b[0m: Cannot initialize a EGL device display. This likely means that your EGL driver does not support the PLATFORM_DEVICE extension, which is required for creating a headless rendering context."
     ]
    }
   ],
   "source": [
    "from orion.algos.human_video_oogs import HumanVideoOOGs\n",
    "from orion.algos.oog import OpenWorldObjectSceneGraph\n",
    "from orion.utils.misc_utils import *\n",
    "from orion.utils.o3d_utils import *\n",
    "human_video_oogs = HumanVideoOOGs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'human_video_oogs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m human_video_annotation_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mannotations/human_demo/iphone_place_chip_bag_on_plate_1_demo\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;66;03m# iphone_front_boat_demo\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mhuman_video_oogs\u001b[49m\u001b[38;5;241m.\u001b[39minit()\n\u001b[1;32m      3\u001b[0m human_video_oogs\u001b[38;5;241m.\u001b[39mgenerate_from_human_video(human_video_annotation_path)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'human_video_oogs' is not defined"
     ]
    }
   ],
   "source": [
    "human_video_annotation_path = \"annotations/human_demo/iphone_place_chip_bag_on_plate_1_demo\" # iphone_front_boat_demo\n",
    "human_video_oogs.init()\n",
    "human_video_oogs.generate_from_human_video(human_video_annotation_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 3\n",
    "\n",
    "human_video_oogs.get_graph(0).draw_overlay_image(mode=\"object\")\n",
    "\n",
    "input_annotation = human_video_oogs.get_graph(idx).input_annotation\n",
    "overlay_image = overlay_xmem_mask_on_image(\n",
    "                human_video_oogs.get_graph(idx).input_image, \n",
    "                human_video_oogs.get_graph(idx).input_annotation,\n",
    "                use_white_bg=False,\n",
    "                rgb_alpha=0.3)\n",
    "\n",
    "\n",
    "\n",
    "overlay_image = overlay_image * (input_annotation == 0)[..., None] + human_video_oogs.get_graph(idx).input_image * (input_annotation != 0)[..., None]\n",
    "plotly_draw_image(overlay_image, width=640, height=480)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_video_annotation_path = \"annotations/human_demo/iphone_front_boat_demo\" # iphone_front_boat_demo\n",
    "human_video_oogs.init()\n",
    "human_video_oogs.generate_from_human_video(human_video_annotation_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Source image and depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotly_draw_image(human_video_oogs.get_graph(2).input_image, width=640, height=480)\n",
    "plotly_draw_image(human_video_oogs.get_graph(1).input_depth, width=640, height=480)\n",
    "human_video_oogs.get_graph(0).draw_overlay_image(mode=\"point\", width=640, height=480, default_point_color=\"rgb(30, 122, 122)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw the scene and the objects from human video\n",
    "1. Draw the scene\n",
    "2. Draw the scene with objects being annotated with segmentation mask\n",
    "3. Trajectories that show the 3D motion of the objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_video_oogs.get_graph(1).draw_scene_3d(downsample=False, \n",
    "                                            depth_trunc=1.0,  \n",
    "                                            use_white_bg=True,\n",
    "                                            no_background=True, \n",
    "                                            overlay_annotation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajs = human_video_oogs.get_graph(1).get_world_trajs(object_ids=[2])\n",
    "trajs = np.delete(trajs, 34, axis=0)\n",
    "human_video_oogs.get_graph(1).draw_objects_list_3d(object_ids=[1, 2], downsample=False, no_background=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajs = human_video_oogs.get_graph(1).get_world_trajs(object_ids=[2])\n",
    "trajs = np.delete(trajs, [10, 17], axis=0)\n",
    "human_video_oogs.get_graph(1).draw_scene_3d(\n",
    "                                            additional_points=trajs,\n",
    "                                            downsample=False, no_background=True,\n",
    "                                            depth_trunc=1.0,  overlay_annotation=True, \n",
    "                                            additional_point_draw_lines=True,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw individual object point clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_video_oogs.get_graph(1).draw_objects_3d(object_id=2, downsample=False,  no_background=True, draw_keypoints=True, keypoints_rgb_str=\"(30, 200, 200)\", uniform_color=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajs = human_video_oogs.get_graph(1).get_world_trajs(object_ids=[1])\n",
    "trajs = np.delete(trajs, [10, 17], axis=0)\n",
    "human_video_oogs.get_graph(1).draw_objects_3d(object_id=1, downsample=False,  no_background=True, draw_trajs=False, additional_point_draw_lines=True, keypoints_rgb_str=\"(30, 122, 122)\", \n",
    "                                              additional_points=trajs, \n",
    "                                              uniform_color=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trimesh\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Load the .obj file using trimesh\n",
    "mesh = trimesh.load('annotations/human_demo/iphone_front_boat_demo/hamer_output/0039_0.obj')\n",
    "\n",
    "# Extract vertices and faces\n",
    "vertices = mesh.vertices\n",
    "faces = mesh.faces\n",
    "\n",
    "# Create a 3D plot\n",
    "fig = go.Figure(data=[go.Mesh3d(x=vertices[:, 0], y=vertices[:, 1], z=vertices[:, 2], \n",
    "                                i=faces[:, 0], j=faces[:, 1], k=faces[:, 2], \n",
    "                                 opacity=0.50)])\n",
    "\n",
    "# Adjust the camera view as desired\n",
    "fig.update_layout(scene_camera=dict(\n",
    "    eye=dict(x=1.5, y=1.5, z=1.5)  # Example camera position\n",
    "),\n",
    "        scene=dict(\n",
    "            xaxis=dict(showbackground=False, zeroline=False, showgrid=False, showticklabels=False, showaxeslabels=False, visible=False),\n",
    "            yaxis=dict(showbackground=False, zeroline=False, showgrid=False, showticklabels=False, showaxeslabels=False, visible=False),\n",
    "            zaxis=dict(showbackground=False, zeroline=False, showgrid=False, showticklabels=False, showaxeslabels=False, visible=False),\n",
    "        ),\n",
    "        paper_bgcolor='rgba(0,0,0,0)',  # Transparent background\n",
    "        plot_bgcolor='rgba(0,0,0,0)',  # Transparent background\n",
    "        margin=dict(l=0, r=0, b=0, t=0),  # No margins\n",
    "        showlegend=False,\n",
    ")\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
